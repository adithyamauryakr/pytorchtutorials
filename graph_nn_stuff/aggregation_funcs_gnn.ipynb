{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithyamauryakr/pytorchtutorials/blob/main/dataset_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "id": "ht58aSyXoAme",
        "outputId": "352bc788-2a8e-4e17-f570-862be06ce7e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid"
      ],
      "metadata": {
        "id": "p6HIELy6ntO-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Planetoid(root='tutorial1', name='Cora')"
      ],
      "metadata": {
        "id": "MCF87kbEn42s",
        "outputId": "570a72af-6c3b-4dda-e11f-e0ef04620f1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cora: different papers and how they are cited among them\n",
        "\n",
        "Dataset properties:"
      ],
      "metadata": {
        "id": "dLNcWQyAovH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)\n",
        "print('no of graphs: \\t\\t', len(dataset))\n",
        "print('no of clases: \\t\\t', dataset.num_classes)\n",
        "print('no of node features:\\t', dataset.num_node_features)\n",
        "print('no of edge features: \\t', dataset.num_edge_features)"
      ],
      "metadata": {
        "id": "3Ezwk6KVoNfi",
        "outputId": "8360aee0-20c4-495c-f3f9-45194d81a7a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cora()\n",
            "no of graphs: \t\t 1\n",
            "no of clases: \t\t 7\n",
            "no of node features:\t 1433\n",
            "no of edge features: \t 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset shapes"
      ],
      "metadata": {
        "id": "tixSzCfVo8TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.data)"
      ],
      "metadata": {
        "id": "xytrdq1zooN7",
        "outputId": "e0b5e0ce-bdb1-4538-b8dd-2e2f4d42fd2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('edge index: \\t\\t', dataset.edge_index.shape)\n",
        "print(dataset.data.edge_index)\n",
        "print('\\n')\n",
        "print(\n",
        "    'train_mask: \\t\\t', dataset.train_mask.shape,\n",
        "    '\\n',\n",
        "    dataset.data.train_mask,\n",
        "    '\\n',\n",
        "    'x:\\t\\t', dataset.data.x.shape,\n",
        "    '\\n',\n",
        "    dataset.data.x,\n",
        "    '\\n',\n",
        "    'y:\\t\\t', dataset.data.y.shape,\n",
        "    '\\n',\n",
        "    dataset.data.y\n",
        ")"
      ],
      "metadata": {
        "id": "6L_h9L18pGNn",
        "outputId": "98996a50-bedb-43b6-ceaa-e82acd0cb4d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edge index: \t\t torch.Size([2, 10556])\n",
            "tensor([[ 633, 1862, 2582,  ...,  598, 1473, 2706],\n",
            "        [   0,    0,    0,  ..., 2707, 2707, 2707]])\n",
            "\n",
            "\n",
            "train_mask: \t\t torch.Size([2708]) \n",
            " tensor([ True,  True,  True,  ..., False, False, False]) \n",
            " x:\t\t torch.Size([2708, 1433]) \n",
            " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) \n",
            " y:\t\t torch.Size([2708]) \n",
            " tensor([3, 4, 4,  ..., 3, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv"
      ],
      "metadata": {
        "id": "oZGSH289pP6U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "nQ64wOPbqiXx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    self.conv = SAGEConv(dataset.num_features,\n",
        "                         dataset.num_classes,\n",
        "                         aggr='max') # max, mean, add ...\n",
        "\n",
        "  def forward(self):\n",
        "    x = self.conv(data.x, data.edge_index)\n",
        "    return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "G_6f5mrpqmQ8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model, data = Net().to(device), data.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "QfPssHikrKsA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
        "  optimizer.step()\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  logits, accs = model(), []\n",
        "\n",
        "  for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "    pred = logits[mask].max(1)[1]\n",
        "    acc = pred.eq(data.y[mask]).sum().item()/mask.sum().item()\n",
        "    accs.append(acc)\n",
        "  return accs\n"
      ],
      "metadata": {
        "id": "i4FZh7lRriO1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  best_val_acc = test_acc = 0\n",
        "\n",
        "  for epoch in range(1, 100):\n",
        "    train()\n",
        "    _, val_acc, tmp_test_acc = test()\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "      best_val_acc = val_acc\n",
        "      test_acc = tmp_test_acc\n",
        "\n",
        "    log = 'Epoch: {:03d}, Val: {:.4f}, Test: {:.4f}'\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(log.format(epoch, best_val_acc, test_acc))"
      ],
      "metadata": {
        "id": "cuLmq5srsufi",
        "outputId": "62de577e-ac26-4cbf-9064-51a4834b33f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Val: 0.7320, Test: 0.7300\n",
            "Epoch: 020, Val: 0.7320, Test: 0.7300\n",
            "Epoch: 030, Val: 0.7320, Test: 0.7300\n",
            "Epoch: 040, Val: 0.7320, Test: 0.7300\n",
            "Epoch: 050, Val: 0.7320, Test: 0.7300\n",
            "Epoch: 060, Val: 0.7320, Test: 0.7300\n",
            "Epoch: 070, Val: 0.7320, Test: 0.7300\n",
            "Epoch: 080, Val: 0.7320, Test: 0.7300\n",
            "Epoch: 090, Val: 0.7320, Test: 0.7300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehL-489ztagj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}