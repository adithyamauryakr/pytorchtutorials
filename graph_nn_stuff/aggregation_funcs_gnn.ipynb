{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithyamauryakr/pytorchtutorials/blob/main/graph_nn_stuff/aggregation_funcs_gnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric torch_scatter"
      ],
      "metadata": {
        "id": "ht58aSyXoAme",
        "outputId": "4c3125ac-8679-4e88-f0b9-ed77d991ae3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torch_scatter\n",
            "  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=547368 sha256=59d96437f18d7d382d8d086fe352d19238ec6037046c9a5d7c809f2e87da7981\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "Successfully built torch_scatter\n",
            "Installing collected packages: torch_scatter, torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1 torch_scatter-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid"
      ],
      "metadata": {
        "id": "p6HIELy6ntO-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn import MessagePassing"
      ],
      "metadata": {
        "id": "yUSAKCo6b1NJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(MessagePassing)"
      ],
      "metadata": {
        "id": "UUoalu-mb9bW",
        "outputId": "65990b32-a661-457b-bb19-7334330d895f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SUPPORTS_FUSED_EDGE_INDEX',\n",
              " 'T_destination',\n",
              " '__annotations__',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_apply',\n",
              " '_call_impl',\n",
              " '_check_input',\n",
              " '_collect',\n",
              " '_compiled_call_impl',\n",
              " '_get_backward_hooks',\n",
              " '_get_backward_pre_hooks',\n",
              " '_get_edge_updater_signature',\n",
              " '_get_name',\n",
              " '_get_propagate_signature',\n",
              " '_index_select',\n",
              " '_index_select_safe',\n",
              " '_lift',\n",
              " '_load_from_state_dict',\n",
              " '_maybe_warn_non_full_backward_hook',\n",
              " '_named_members',\n",
              " '_register_load_state_dict_pre_hook',\n",
              " '_register_state_dict_hook',\n",
              " '_replicate_for_data_parallel',\n",
              " '_save_to_state_dict',\n",
              " '_set_jittable_templates',\n",
              " '_set_size',\n",
              " '_slow_forward',\n",
              " '_version',\n",
              " '_wrapped_call_impl',\n",
              " 'add_module',\n",
              " 'aggregate',\n",
              " 'apply',\n",
              " 'bfloat16',\n",
              " 'buffers',\n",
              " 'call_super_init',\n",
              " 'children',\n",
              " 'compile',\n",
              " 'cpu',\n",
              " 'cuda',\n",
              " 'decomposed_layers',\n",
              " 'double',\n",
              " 'dump_patches',\n",
              " 'edge_update',\n",
              " 'edge_updater',\n",
              " 'eval',\n",
              " 'explain',\n",
              " 'explain_message',\n",
              " 'extra_repr',\n",
              " 'float',\n",
              " 'forward',\n",
              " 'get_buffer',\n",
              " 'get_extra_state',\n",
              " 'get_parameter',\n",
              " 'get_submodule',\n",
              " 'half',\n",
              " 'ipu',\n",
              " 'jittable',\n",
              " 'load_state_dict',\n",
              " 'message',\n",
              " 'message_and_aggregate',\n",
              " 'modules',\n",
              " 'mtia',\n",
              " 'named_buffers',\n",
              " 'named_children',\n",
              " 'named_modules',\n",
              " 'named_parameters',\n",
              " 'parameters',\n",
              " 'propagate',\n",
              " 'register_aggregate_forward_hook',\n",
              " 'register_aggregate_forward_pre_hook',\n",
              " 'register_backward_hook',\n",
              " 'register_buffer',\n",
              " 'register_edge_update_forward_hook',\n",
              " 'register_edge_update_forward_pre_hook',\n",
              " 'register_forward_hook',\n",
              " 'register_forward_pre_hook',\n",
              " 'register_full_backward_hook',\n",
              " 'register_full_backward_pre_hook',\n",
              " 'register_load_state_dict_post_hook',\n",
              " 'register_load_state_dict_pre_hook',\n",
              " 'register_message_and_aggregate_forward_hook',\n",
              " 'register_message_and_aggregate_forward_pre_hook',\n",
              " 'register_message_forward_hook',\n",
              " 'register_message_forward_pre_hook',\n",
              " 'register_module',\n",
              " 'register_parameter',\n",
              " 'register_propagate_forward_hook',\n",
              " 'register_propagate_forward_pre_hook',\n",
              " 'register_state_dict_post_hook',\n",
              " 'register_state_dict_pre_hook',\n",
              " 'requires_grad_',\n",
              " 'reset_parameters',\n",
              " 'set_extra_state',\n",
              " 'set_submodule',\n",
              " 'share_memory',\n",
              " 'special_args',\n",
              " 'state_dict',\n",
              " 'to',\n",
              " 'to_empty',\n",
              " 'train',\n",
              " 'type',\n",
              " 'update',\n",
              " 'xpu',\n",
              " 'zero_grad']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GINConv\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "import torch_scatter\n",
        "\n",
        "\n",
        "class AbstractLAFLayer(torch.nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AbstractLAFLayer, self).__init__()\n",
        "        assert 'units' in kwargs or 'weights' in kwargs\n",
        "        if 'device' in kwargs.keys():\n",
        "            self.device = kwargs['device']\n",
        "        else:\n",
        "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.ngpus = torch.cuda.device_count()\n",
        "\n",
        "        if 'kernel_initializer' in kwargs.keys():\n",
        "            assert kwargs['kernel_initializer'] in [\n",
        "                'random_normal',\n",
        "                'glorot_normal',\n",
        "                'he_normal',\n",
        "                'random_uniform',\n",
        "                'glorot_uniform',\n",
        "                'he_uniform']\n",
        "            self.kernel_initializer = kwargs['kernel_initializer']\n",
        "        else:\n",
        "            self.kernel_initializer = 'random_normal'\n",
        "\n",
        "        if 'weights' in kwargs.keys():\n",
        "            self.weights = Parameter(kwargs['weights'].to(self.device), \\\n",
        "                                     requires_grad=True)\n",
        "            self.units = self.weights.shape[1]\n",
        "        else:\n",
        "            self.units = kwargs['units']\n",
        "            params = torch.empty(12, self.units, device=self.device)\n",
        "            if self.kernel_initializer == 'random_normal':\n",
        "                torch.nn.init.normal_(params)\n",
        "            elif self.kernel_initializer == 'glorot_normal':\n",
        "                torch.nn.init.xavier_normal_(params)\n",
        "            elif self.kernel_initializer == 'he_normal':\n",
        "                torch.nn.init.kaiming_normal_(params)\n",
        "            elif self.kernel_initializer == 'random_uniform':\n",
        "                torch.nn.init.uniform_(params)\n",
        "            elif self.kernel_initializer == 'glorot_uniform':\n",
        "                torch.nn.init.xavier_uniform_(params)\n",
        "            elif self.kernel_initializer == 'he_uniform':\n",
        "                torch.nn.init.kaiming_uniform_(params)\n",
        "            self.weights = Parameter(params, \\\n",
        "                                     requires_grad=True)\n",
        "        e = torch.tensor([1,-1,1,-1], dtype=torch.float32, device=self.device)\n",
        "        self.e = Parameter(e, requires_grad=False)\n",
        "        num_idx = torch.tensor([1,1,0,0], dtype=torch.float32, device=self.device).\\\n",
        "                                view(1,1,-1,1)\n",
        "        self.num_idx = Parameter(num_idx, requires_grad=False)\n",
        "        den_idx = torch.tensor([0,0,1,1], dtype=torch.float32, device=self.device).\\\n",
        "                                view(1,1,-1,1)\n",
        "        self.den_idx = Parameter(den_idx, requires_grad=False)\n",
        "\n",
        "\n",
        "class LAFLayer(AbstractLAFLayer):\n",
        "    def __init__(self, eps=1e-7, **kwargs):\n",
        "        super(LAFLayer, self).__init__(**kwargs)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, data, index, dim=0, **kwargs):\n",
        "        eps = self.eps\n",
        "        sup = 1.0 - eps\n",
        "        e = self.e\n",
        "\n",
        "        x = torch.clamp(data, eps, sup)\n",
        "        x = torch.unsqueeze(x, -1)\n",
        "        e = e.view(1,1,-1)\n",
        "\n",
        "        exps = (1. - e)/2. + x*e\n",
        "        exps = torch.unsqueeze(exps, -1)\n",
        "        exps = torch.pow(exps, torch.relu(self.weights[0:4]))\n",
        "\n",
        "        scatter = torch_scatter.scatter_add(exps, index.view(-1), dim=dim)\n",
        "        scatter = torch.clamp(scatter, eps)\n",
        "\n",
        "        sqrt = torch.pow(scatter, torch.relu(self.weights[4:8]))\n",
        "        alpha_beta = self.weights[8:12].view(1,1,4,-1)\n",
        "        terms = sqrt * alpha_beta\n",
        "\n",
        "        num = torch.sum(terms * self.num_idx, dim=2)\n",
        "        den = torch.sum(terms * self.den_idx, dim=2)\n",
        "\n",
        "        multiplier = 2.0*torch.clamp(torch.sign(den), min=0.0) - 1.0\n",
        "\n",
        "        den = torch.where((den < eps) & (den > -eps), multiplier*eps, den)\n",
        "\n",
        "        res = num / den\n",
        "        return res"
      ],
      "metadata": {
        "id": "kw3pjNXvcHut"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LAF Aggregation"
      ],
      "metadata": {
        "id": "0MIq6pMBeZrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GINLAFConv(GINConv):\n",
        "  def __init_(self, nn, units=1, node_dim=32, **kwargs):\n",
        "\n",
        "    super(GINLAFConv, self).__init__(nn, **kwargs)\n",
        "    self.laf = LAFLayer(units=units, kernel_initializer='random_uniform')\n",
        "    self.mlp = torch.nn.Linear(node_dim*units, node_dim)\n",
        "    self.dim = node_dim\n",
        "    self.units = units\n",
        "\n",
        "  def aggregate(self, input, index):\n",
        "    x = torch.sigmoid(inputs)\n",
        "    x = self.laf(x, index)\n",
        "    x = x.view((-1, self.dim*self.units))\n",
        "    x = self.mlp(x)\n",
        "\n",
        "    return(x)"
      ],
      "metadata": {
        "id": "RGjuK4tcc2AR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PNA Aggregation"
      ],
      "metadata": {
        "id": "z6EORacMMdxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GINPNAConv(GINConv):\n",
        "  def __init__(self, nn, node_dim = 32, **kwargs):\n",
        "    super(GINPNAConv, self).__init__(nn, **kwargs)\n",
        "    self.mlp = torch.nn.Linear(node_dim*12, node_dim)\n",
        "    self.delta = 2.5749\n",
        "\n",
        "  def aggregate(self, inputs, index):\n",
        "    sums = torch_scatter.scatter_add(inputs, index, dim=0)\n",
        "    maxs = torch_scatter.scatter_max(inputs, index, dim=0)\n",
        "    means = torch_scatter.scatter_mean(inputs, index, dim=0)\n",
        "    var = torch.relu(torch_scatter.scatter_mean(inputs**2, index, dim-0)-means**2)\n",
        "\n",
        "    aggrs = [sums, maxs, means, var]\n",
        "    c_idx = index.bincount().float().view(-1, 1)\n",
        "    l_idx = torch.log(c_idx + 1.)\n",
        "\n",
        "    amplication_scaler = [c_idx/self.delta*a for a in aggrs]\n",
        "    attenuation_scaler = [self.data/c_idx * a for a in aggrs]\n",
        "    combinations = torch.cat(aggrs+amplication_scaler+attenuation_scaler, dim=1)\n",
        "    x = self.mlp(combinations)\n",
        "    return x"
      ],
      "metadata": {
        "id": "AzUrvMScMdUA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test for new classes"
      ],
      "metadata": {
        "id": "PezEgZrlOVt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import MessagePassing, SAGEConv, GINConv, global_add_pool\n",
        "import torch_scatter\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "import os.path as osp"
      ],
      "metadata": {
        "id": "OesOuMacOYQm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = osp.join('./', 'data', 'TU')\n",
        "dataset = TUDataset(path, name='MUTAG').shuffle()\n",
        "test_dataset = dataset[:len(dataset)//10]\n",
        "train_dataset = dataset[len(dataset)//10:]\n",
        "test_loader = DataLoader(test_dataset, batch_size =128)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n"
      ],
      "metadata": {
        "id": "gMwmFRsDPEk3",
        "outputId": "4674922d-8b34-407b-81b6-6aa51996730c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LAFNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LAFNet, self).__init__()\n",
        "\n",
        "    num_features = dataset.num_features\n",
        "    dim = 32\n",
        "    units = 3\n",
        "\n",
        "    nn1 = Sequential(\n",
        "        Linear(num_features, dim), ReLU(), Linear(dim,dim)\n",
        "    )\n",
        "    self.conv1 = GINLAFConv(nn1, units=units, node_dim=num_features)\n",
        "    self.bn1 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "    nn2 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv2 = GINLAFConv(nn2, units=units, node_dim= dim)\n",
        "    self.bn2 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "    nn3 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv3 = GINLAFConv(nn3, units=units, node_dim=dim)\n",
        "    self.bn3 = self.BatchNorm1d(dim)\n",
        "\n",
        "    nn4 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv4 = GINLAFConv(nn4, units=units, node_dim=dim)\n",
        "    self.bn4 = self.BatchNorm1d(dim)\n",
        "\n",
        "    nn5 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv5 = GINLAFConv(nn5, units=units, node_dim=dim)\n",
        "    self.bn5 = self.BatchNorm1d(dim)\n",
        "\n",
        "    self.fc1 = Linear(dim, dim)\n",
        "    self.fc2 = Linear(dim, dataset.num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    x = F.relu(self.conv1(x, edge_index))\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(self.conv2(x, edge_index))\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(self.conv3(x, edge_index))\n",
        "    x = self.bn3(x)\n",
        "    x = F.relu(self.conv4(x, edge_index))\n",
        "    x = self.bn4(x)\n",
        "    x = F.relu(self.conv5(x, edge_index))\n",
        "    x = self.bn5(x)\n",
        "    x = global_add_pool(x, batch)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "S6VS7bJgPlTC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PNANet(torch.nn.Module):\n",
        "  def __init(self):\n",
        "    super(PNANet, self).__init__()\n",
        "\n",
        "    num_features = dataset.num_features\n",
        "    dim = 32\n",
        "\n",
        "    nn1 = Sequential(\n",
        "        Linear(num_features, dim), ReLU(), Linear(dim,dim)\n",
        "    )\n",
        "    self.conv1 = GINPNAConv(nn1, node_dim=num_features)\n",
        "    self.bn1 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "    nn2 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv2 = GINPNAConv(nn2, node_dim=dim)\n",
        "    self.bn2 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "    nn3 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv3 = GINPNAConv(nn3, node_dim=dim)\n",
        "    self.bn3 = self.BatchNorm1d(dim)\n",
        "\n",
        "    nn4 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv4 = GINPNAConv(nn4, node_dim=dim)\n",
        "    self.bn4 = self.BatchNorm1d(dim)\n",
        "\n",
        "    nn5 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv5 = GINPNAConv(nn5, node_dim=dim)\n",
        "    self.bn5 = self.BatchNorm1d(dim)\n",
        "\n",
        "    self.fc1 = Linear(dim, dim)\n",
        "    self.fc2 = Linear(dim, dataset.num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    x = F.relu(self.conv1(x, edge_index))\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(self.conv2(x, edge_index))\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(self.conv3(x, edge_index))\n",
        "    x = self.bn3(x)\n",
        "    x = F.relu(self.conv4(x, edge_index))\n",
        "    x = self.bn4(x)\n",
        "    x = F.relu(self.conv5(x, edge_index))\n",
        "    x = self.bn5(x)\n",
        "    x = global_add_pool(x, batch)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "w1zGalEhYJAh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GINNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GINNet, self).__init__()\n",
        "\n",
        "    num_features = dataset.num_features\n",
        "    dim = 32\n",
        "\n",
        "    nn1 = Sequential(\n",
        "        Linear(num_features, dim), ReLU(), Linear(dim,dim)\n",
        "    )\n",
        "    self.conv1 = GINConv(nn1)\n",
        "    self.bn1 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "    nn2 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv2 = GINConv(nn2)\n",
        "    self.bn2 = torch.nn.BatchNorm1d(dim)\n",
        "\n",
        "    nn3 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv3 = GINConv(nn3)\n",
        "    self.bn3 = self.BatchNorm1d(dim)\n",
        "\n",
        "    nn4 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv4 = GINConv(nn4)\n",
        "    self.bn4 = self.BatchNorm1d(dim)\n",
        "\n",
        "    nn5 = Sequential(\n",
        "        Linear(dim, dim), ReLU(), Linear(dim, dim)\n",
        "    )\n",
        "    self.conv5 = GINConv(nn5)\n",
        "    self.bn5 = self.BatchNorm1d(dim)\n",
        "\n",
        "    self.fc1 = Linear(dim, dim)\n",
        "    self.fc2 = Linear(dim, dataset.num_classes)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    x = F.relu(self.conv1(x, edge_index))\n",
        "    x = self.bn1(x)\n",
        "    x = F.relu(self.conv2(x, edge_index))\n",
        "    x = self.bn2(x)\n",
        "    x = F.relu(self.conv3(x, edge_index))\n",
        "    x = self.bn3(x)\n",
        "    x = F.relu(self.conv4(x, edge_index))\n",
        "    x = self.bn4(x)\n",
        "    x = F.relu(self.conv5(x, edge_index))\n",
        "    x = self.bn5(x)\n",
        "    x = global_add_pool(x, batch)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x, dim=1)\n",
        ""
      ],
      "metadata": {
        "id": "c_eQ3GuaaMa3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# net = 'PNA'\n",
        "\n",
        "# if net == 'LAF':\n",
        "#   model = LAFNet().to(device)\n",
        "if net == 'PNA':\n",
        "  model = PNANet().to(device)\n",
        "else:\n",
        "  model = GINNet().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def  train(epoch):\n",
        "  model.train()\n",
        "\n",
        "  if epoch == 51:\n",
        "    for param_group in optimizer.param_groups:\n",
        "      param_group['lr'] = 0.5*param_group['lr']\n",
        "\n",
        "  loss_all = 0\n",
        "  for data in train_loader:\n",
        "    data = data.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data.x, data.edge_index, data.batch)\n",
        "    loss = F.nll_loss(output, data.y)\n",
        "    loss.backward()\n",
        "    loss_all += loss.item()*data.num_graphs\n",
        "    optimizer.step()\n",
        "\n",
        "  return loss_all/len(train_dataset)\n",
        "\n",
        "def test(loader):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  for data in loader:\n",
        "    data = data.to(device)\n",
        "    output = model(data.x, data.edge_index, data.batch)\n",
        "    pred = output.max(dim=1)[1]\n",
        "    correct += pred.eg(data.y).sum().item()\n",
        "\n",
        "  return correct/len(loader.dataset)\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "  train_loss = train(epoch)\n",
        "  train_acc = test(train_loader)\n",
        "  test_acc = test(test_loader)\n",
        "  print(\"Epoch: {:03d}, Train Loss: {:.7f}, \" \"Train Acc: {:.7f}, Test Acc: {:.7f}\". format(epoch, train_loss, train_acc, test_acc))"
      ],
      "metadata": {
        "id": "6vLegaLWan3c",
        "outputId": "042f9d59-405c-45e1-a521-ca61855674c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GINNet' object has no attribute 'BatchNorm1d'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-785e8d0b0a72>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPNANet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGINNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-19c18b1b7248>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     23\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGINConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     nn4 = Sequential(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GINNet' object has no attribute 'BatchNorm1d'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nqJNKSNNc9Vr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}